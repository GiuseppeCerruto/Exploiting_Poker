import os
from matplotlib import pyplot as plt
from rlcard.agents import RandomAgent, DQNAgent, PDQNAgent, NFSPAgent


def create_dirs(section, typ):
    current = os.getcwd()

    models = typ + '_' + section
    dirs = os.listdir(current)
    if models not in dirs:
        os.makedirs(models)

    plots = 'plots_' + section
    dirs = os.listdir(current)
    if plots not in dirs:
        os.makedirs(plots)

def plot(typ, game, rew_list, num_player, save_dir):
    plt.title(f'{game[0].upper() + game[1:]} with {num_player} players')
    plt.xlabel("Time")
    plt.ylabel("Reward")
    plt.grid(color="#989898", zorder=0)
    for elem, lbl in rew_list:
        times, rews = zip(*elem)
        plt.plot(times, rews, zorder=3, label=lbl)
    
    plt.legend(loc="lower right")
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, typ + '_' + game))
    plt.clf()

def save_base_res(data, save_dir, name):
    f = open(os.path.join(save_dir, name), 'w+')
    for game, algo_data in data:
        s = f'{game[0].upper() + game[1:]}\n\n'
        for algo, players_data in algo_data:
            s += algo
            _, rew = zip(*players_data)
            s += ': ' + ','.join([str(v) for v in rew]) + '\n'
        s += '\n-------------------------------\n\n'
        f.write(s)
    f.close()

def save_base_res_B(data, save_dir, name):
    f = open(os.path.join(save_dir, name), 'w+')
    for game, algo_data in data:
        s = f'{game[0].upper() + game[1:]}\n\n'
        for algo, rew in algo_data:
            s += algo
            s += ': ' + str(rew) + '\n'
        s += '\n-------------------------------\n\n'
        f.write(s)
    f.close()

def get_agent(game, algorithm, env, device):
    if algorithm == 'DQN':
        return DQNAgent(num_actions=env.num_actions,
                        state_shape=env.state_shape[0],
                        mlp_layers=[128,128],
                        device=device)
    if algorithm == 'PDQN':
        return PDQNAgent(num_actions=env.num_actions,
                        state_shape=env.state_shape[0],
                        mlp_layers=[128,128],
                        device=device)
    if algorithm == 'NFSP':
        if game == 'limit-holdem':
            return NFSPAgent(num_actions=env.num_actions,
                        state_shape=env.state_shape[0],
                        hidden_layers_sizes=[128,128,128],
                        q_mlp_layers=[128,128],
                        device=device)
        else:
            return NFSPAgent(num_actions=env.num_actions,
                        state_shape=env.state_shape[0],
                        hidden_layers_sizes=[16,32,16],
                        q_mlp_layers=[64,64],
                        device=device,
                        anticipatory_param=0.35,
                        rl_learning_rate=0.001)

    return RandomAgent(env.num_actions)
